{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv', names=['REs', 'PrNd', 'La', 'Ce', 'Fe', 'Co', 'B', 'TM', 'PrNd_p', 'La_p', 'Ce_p', 'Hcj'])\n",
    "X = df.iloc[:, :10].values\n",
    "y = df['Hcj'].values\n",
    "X_1 = preprocessing.scale(X)\n",
    "y_1 = preprocessing.scale(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'learning_rate': 0.15000000000000002, 'n_estimators': 100} with a score of 0.86\n",
      "\n",
      "{'learning_rate': 0.15000000000000002, 'n_estimators': 100}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.101 (+/-0.057) for {'learning_rate': 0.01, 'n_estimators': 10}\n",
      "0.202 (+/-0.069) for {'learning_rate': 0.01, 'n_estimators': 20}\n",
      "0.282 (+/-0.079) for {'learning_rate': 0.01, 'n_estimators': 30}\n",
      "0.354 (+/-0.087) for {'learning_rate': 0.01, 'n_estimators': 40}\n",
      "0.416 (+/-0.087) for {'learning_rate': 0.01, 'n_estimators': 50}\n",
      "0.464 (+/-0.098) for {'learning_rate': 0.01, 'n_estimators': 60}\n",
      "0.511 (+/-0.094) for {'learning_rate': 0.01, 'n_estimators': 70}\n",
      "0.547 (+/-0.093) for {'learning_rate': 0.01, 'n_estimators': 80}\n",
      "0.578 (+/-0.090) for {'learning_rate': 0.01, 'n_estimators': 90}\n",
      "0.605 (+/-0.091) for {'learning_rate': 0.01, 'n_estimators': 100}\n",
      "0.629 (+/-0.098) for {'learning_rate': 0.01, 'n_estimators': 110}\n",
      "0.201 (+/-0.074) for {'learning_rate': 0.02, 'n_estimators': 10}\n",
      "0.354 (+/-0.103) for {'learning_rate': 0.02, 'n_estimators': 20}\n",
      "0.463 (+/-0.107) for {'learning_rate': 0.02, 'n_estimators': 30}\n",
      "0.541 (+/-0.096) for {'learning_rate': 0.02, 'n_estimators': 40}\n",
      "0.604 (+/-0.090) for {'learning_rate': 0.02, 'n_estimators': 50}\n",
      "0.649 (+/-0.088) for {'learning_rate': 0.02, 'n_estimators': 60}\n",
      "0.683 (+/-0.090) for {'learning_rate': 0.02, 'n_estimators': 70}\n",
      "0.710 (+/-0.070) for {'learning_rate': 0.02, 'n_estimators': 80}\n",
      "0.731 (+/-0.078) for {'learning_rate': 0.02, 'n_estimators': 90}\n",
      "0.745 (+/-0.074) for {'learning_rate': 0.02, 'n_estimators': 100}\n",
      "0.757 (+/-0.081) for {'learning_rate': 0.02, 'n_estimators': 110}\n",
      "0.281 (+/-0.094) for {'learning_rate': 0.029999999999999999, 'n_estimators': 10}\n",
      "0.462 (+/-0.096) for {'learning_rate': 0.029999999999999999, 'n_estimators': 20}\n",
      "0.581 (+/-0.096) for {'learning_rate': 0.029999999999999999, 'n_estimators': 30}\n",
      "0.652 (+/-0.080) for {'learning_rate': 0.029999999999999999, 'n_estimators': 40}\n",
      "0.697 (+/-0.080) for {'learning_rate': 0.029999999999999999, 'n_estimators': 50}\n",
      "0.727 (+/-0.072) for {'learning_rate': 0.029999999999999999, 'n_estimators': 60}\n",
      "0.753 (+/-0.074) for {'learning_rate': 0.029999999999999999, 'n_estimators': 70}\n",
      "0.768 (+/-0.070) for {'learning_rate': 0.029999999999999999, 'n_estimators': 80}\n",
      "0.786 (+/-0.073) for {'learning_rate': 0.029999999999999999, 'n_estimators': 90}\n",
      "0.788 (+/-0.074) for {'learning_rate': 0.029999999999999999, 'n_estimators': 100}\n",
      "0.798 (+/-0.080) for {'learning_rate': 0.029999999999999999, 'n_estimators': 110}\n",
      "0.355 (+/-0.097) for {'learning_rate': 0.040000000000000001, 'n_estimators': 10}\n",
      "0.538 (+/-0.094) for {'learning_rate': 0.040000000000000001, 'n_estimators': 20}\n",
      "0.655 (+/-0.083) for {'learning_rate': 0.040000000000000001, 'n_estimators': 30}\n",
      "0.710 (+/-0.081) for {'learning_rate': 0.040000000000000001, 'n_estimators': 40}\n",
      "0.747 (+/-0.079) for {'learning_rate': 0.040000000000000001, 'n_estimators': 50}\n",
      "0.773 (+/-0.075) for {'learning_rate': 0.040000000000000001, 'n_estimators': 60}\n",
      "0.786 (+/-0.082) for {'learning_rate': 0.040000000000000001, 'n_estimators': 70}\n",
      "0.796 (+/-0.072) for {'learning_rate': 0.040000000000000001, 'n_estimators': 80}\n",
      "0.804 (+/-0.078) for {'learning_rate': 0.040000000000000001, 'n_estimators': 90}\n",
      "0.806 (+/-0.076) for {'learning_rate': 0.040000000000000001, 'n_estimators': 100}\n",
      "0.817 (+/-0.061) for {'learning_rate': 0.040000000000000001, 'n_estimators': 110}\n",
      "0.418 (+/-0.093) for {'learning_rate': 0.050000000000000003, 'n_estimators': 10}\n",
      "0.611 (+/-0.096) for {'learning_rate': 0.050000000000000003, 'n_estimators': 20}\n",
      "0.695 (+/-0.087) for {'learning_rate': 0.050000000000000003, 'n_estimators': 30}\n",
      "0.748 (+/-0.078) for {'learning_rate': 0.050000000000000003, 'n_estimators': 40}\n",
      "0.773 (+/-0.080) for {'learning_rate': 0.050000000000000003, 'n_estimators': 50}\n",
      "0.791 (+/-0.083) for {'learning_rate': 0.050000000000000003, 'n_estimators': 60}\n",
      "0.803 (+/-0.083) for {'learning_rate': 0.050000000000000003, 'n_estimators': 70}\n",
      "0.813 (+/-0.074) for {'learning_rate': 0.050000000000000003, 'n_estimators': 80}\n",
      "0.820 (+/-0.073) for {'learning_rate': 0.050000000000000003, 'n_estimators': 90}\n",
      "0.820 (+/-0.072) for {'learning_rate': 0.050000000000000003, 'n_estimators': 100}\n",
      "0.831 (+/-0.068) for {'learning_rate': 0.050000000000000003, 'n_estimators': 110}\n",
      "0.469 (+/-0.102) for {'learning_rate': 0.060000000000000005, 'n_estimators': 10}\n",
      "0.646 (+/-0.109) for {'learning_rate': 0.060000000000000005, 'n_estimators': 20}\n",
      "0.723 (+/-0.087) for {'learning_rate': 0.060000000000000005, 'n_estimators': 30}\n",
      "0.772 (+/-0.073) for {'learning_rate': 0.060000000000000005, 'n_estimators': 40}\n",
      "0.794 (+/-0.081) for {'learning_rate': 0.060000000000000005, 'n_estimators': 50}\n",
      "0.802 (+/-0.076) for {'learning_rate': 0.060000000000000005, 'n_estimators': 60}\n",
      "0.815 (+/-0.077) for {'learning_rate': 0.060000000000000005, 'n_estimators': 70}\n",
      "0.822 (+/-0.076) for {'learning_rate': 0.060000000000000005, 'n_estimators': 80}\n",
      "0.821 (+/-0.083) for {'learning_rate': 0.060000000000000005, 'n_estimators': 90}\n",
      "0.830 (+/-0.065) for {'learning_rate': 0.060000000000000005, 'n_estimators': 100}\n",
      "0.836 (+/-0.071) for {'learning_rate': 0.060000000000000005, 'n_estimators': 110}\n",
      "0.508 (+/-0.087) for {'learning_rate': 0.069999999999999993, 'n_estimators': 10}\n",
      "0.684 (+/-0.092) for {'learning_rate': 0.069999999999999993, 'n_estimators': 20}\n",
      "0.756 (+/-0.068) for {'learning_rate': 0.069999999999999993, 'n_estimators': 30}\n",
      "0.788 (+/-0.071) for {'learning_rate': 0.069999999999999993, 'n_estimators': 40}\n",
      "0.796 (+/-0.079) for {'learning_rate': 0.069999999999999993, 'n_estimators': 50}\n",
      "0.824 (+/-0.075) for {'learning_rate': 0.069999999999999993, 'n_estimators': 60}\n",
      "0.821 (+/-0.071) for {'learning_rate': 0.069999999999999993, 'n_estimators': 70}\n",
      "0.824 (+/-0.075) for {'learning_rate': 0.069999999999999993, 'n_estimators': 80}\n",
      "0.830 (+/-0.082) for {'learning_rate': 0.069999999999999993, 'n_estimators': 90}\n",
      "0.839 (+/-0.074) for {'learning_rate': 0.069999999999999993, 'n_estimators': 100}\n",
      "0.841 (+/-0.068) for {'learning_rate': 0.069999999999999993, 'n_estimators': 110}\n",
      "0.550 (+/-0.103) for {'learning_rate': 0.080000000000000002, 'n_estimators': 10}\n",
      "0.712 (+/-0.097) for {'learning_rate': 0.080000000000000002, 'n_estimators': 20}\n",
      "0.775 (+/-0.070) for {'learning_rate': 0.080000000000000002, 'n_estimators': 30}\n",
      "0.786 (+/-0.100) for {'learning_rate': 0.080000000000000002, 'n_estimators': 40}\n",
      "0.810 (+/-0.070) for {'learning_rate': 0.080000000000000002, 'n_estimators': 50}\n",
      "0.823 (+/-0.070) for {'learning_rate': 0.080000000000000002, 'n_estimators': 60}\n",
      "0.832 (+/-0.075) for {'learning_rate': 0.080000000000000002, 'n_estimators': 70}\n",
      "0.834 (+/-0.076) for {'learning_rate': 0.080000000000000002, 'n_estimators': 80}\n",
      "0.834 (+/-0.063) for {'learning_rate': 0.080000000000000002, 'n_estimators': 90}\n",
      "0.844 (+/-0.058) for {'learning_rate': 0.080000000000000002, 'n_estimators': 100}\n",
      "0.844 (+/-0.071) for {'learning_rate': 0.080000000000000002, 'n_estimators': 110}\n",
      "0.592 (+/-0.092) for {'learning_rate': 0.089999999999999997, 'n_estimators': 10}\n",
      "0.729 (+/-0.077) for {'learning_rate': 0.089999999999999997, 'n_estimators': 20}\n",
      "0.782 (+/-0.097) for {'learning_rate': 0.089999999999999997, 'n_estimators': 30}\n",
      "0.806 (+/-0.067) for {'learning_rate': 0.089999999999999997, 'n_estimators': 40}\n",
      "0.808 (+/-0.078) for {'learning_rate': 0.089999999999999997, 'n_estimators': 50}\n",
      "0.829 (+/-0.075) for {'learning_rate': 0.089999999999999997, 'n_estimators': 60}\n",
      "0.832 (+/-0.070) for {'learning_rate': 0.089999999999999997, 'n_estimators': 70}\n",
      "0.837 (+/-0.061) for {'learning_rate': 0.089999999999999997, 'n_estimators': 80}\n",
      "0.836 (+/-0.067) for {'learning_rate': 0.089999999999999997, 'n_estimators': 90}\n",
      "0.835 (+/-0.081) for {'learning_rate': 0.089999999999999997, 'n_estimators': 100}\n",
      "0.850 (+/-0.063) for {'learning_rate': 0.089999999999999997, 'n_estimators': 110}\n",
      "0.620 (+/-0.084) for {'learning_rate': 0.099999999999999992, 'n_estimators': 10}\n",
      "0.743 (+/-0.083) for {'learning_rate': 0.099999999999999992, 'n_estimators': 20}\n",
      "0.787 (+/-0.078) for {'learning_rate': 0.099999999999999992, 'n_estimators': 30}\n",
      "0.812 (+/-0.065) for {'learning_rate': 0.099999999999999992, 'n_estimators': 40}\n",
      "0.822 (+/-0.076) for {'learning_rate': 0.099999999999999992, 'n_estimators': 50}\n",
      "0.826 (+/-0.072) for {'learning_rate': 0.099999999999999992, 'n_estimators': 60}\n",
      "0.831 (+/-0.079) for {'learning_rate': 0.099999999999999992, 'n_estimators': 70}\n",
      "0.837 (+/-0.069) for {'learning_rate': 0.099999999999999992, 'n_estimators': 80}\n",
      "0.849 (+/-0.069) for {'learning_rate': 0.099999999999999992, 'n_estimators': 90}\n",
      "0.841 (+/-0.067) for {'learning_rate': 0.099999999999999992, 'n_estimators': 100}\n",
      "0.846 (+/-0.064) for {'learning_rate': 0.099999999999999992, 'n_estimators': 110}\n",
      "0.642 (+/-0.081) for {'learning_rate': 0.11, 'n_estimators': 10}\n",
      "0.760 (+/-0.055) for {'learning_rate': 0.11, 'n_estimators': 20}\n",
      "0.806 (+/-0.074) for {'learning_rate': 0.11, 'n_estimators': 30}\n",
      "0.818 (+/-0.069) for {'learning_rate': 0.11, 'n_estimators': 40}\n",
      "0.827 (+/-0.077) for {'learning_rate': 0.11, 'n_estimators': 50}\n",
      "0.832 (+/-0.066) for {'learning_rate': 0.11, 'n_estimators': 60}\n",
      "0.839 (+/-0.053) for {'learning_rate': 0.11, 'n_estimators': 70}\n",
      "0.839 (+/-0.067) for {'learning_rate': 0.11, 'n_estimators': 80}\n",
      "0.839 (+/-0.072) for {'learning_rate': 0.11, 'n_estimators': 90}\n",
      "0.841 (+/-0.079) for {'learning_rate': 0.11, 'n_estimators': 100}\n",
      "0.844 (+/-0.070) for {'learning_rate': 0.11, 'n_estimators': 110}\n",
      "0.645 (+/-0.096) for {'learning_rate': 0.12, 'n_estimators': 10}\n",
      "0.769 (+/-0.073) for {'learning_rate': 0.12, 'n_estimators': 20}\n",
      "0.808 (+/-0.075) for {'learning_rate': 0.12, 'n_estimators': 30}\n",
      "0.817 (+/-0.075) for {'learning_rate': 0.12, 'n_estimators': 40}\n",
      "0.830 (+/-0.063) for {'learning_rate': 0.12, 'n_estimators': 50}\n",
      "0.840 (+/-0.075) for {'learning_rate': 0.12, 'n_estimators': 60}\n",
      "0.843 (+/-0.079) for {'learning_rate': 0.12, 'n_estimators': 70}\n",
      "0.835 (+/-0.077) for {'learning_rate': 0.12, 'n_estimators': 80}\n",
      "0.846 (+/-0.058) for {'learning_rate': 0.12, 'n_estimators': 90}\n",
      "0.848 (+/-0.067) for {'learning_rate': 0.12, 'n_estimators': 100}\n",
      "0.854 (+/-0.063) for {'learning_rate': 0.12, 'n_estimators': 110}\n",
      "0.681 (+/-0.093) for {'learning_rate': 0.13, 'n_estimators': 10}\n",
      "0.773 (+/-0.064) for {'learning_rate': 0.13, 'n_estimators': 20}\n",
      "0.806 (+/-0.083) for {'learning_rate': 0.13, 'n_estimators': 30}\n",
      "0.826 (+/-0.070) for {'learning_rate': 0.13, 'n_estimators': 40}\n",
      "0.829 (+/-0.069) for {'learning_rate': 0.13, 'n_estimators': 50}\n",
      "0.834 (+/-0.071) for {'learning_rate': 0.13, 'n_estimators': 60}\n",
      "0.835 (+/-0.074) for {'learning_rate': 0.13, 'n_estimators': 70}\n",
      "0.844 (+/-0.073) for {'learning_rate': 0.13, 'n_estimators': 80}\n",
      "0.843 (+/-0.075) for {'learning_rate': 0.13, 'n_estimators': 90}\n",
      "0.837 (+/-0.070) for {'learning_rate': 0.13, 'n_estimators': 100}\n",
      "0.842 (+/-0.073) for {'learning_rate': 0.13, 'n_estimators': 110}\n",
      "0.693 (+/-0.097) for {'learning_rate': 0.14000000000000001, 'n_estimators': 10}\n",
      "0.794 (+/-0.077) for {'learning_rate': 0.14000000000000001, 'n_estimators': 20}\n",
      "0.814 (+/-0.076) for {'learning_rate': 0.14000000000000001, 'n_estimators': 30}\n",
      "0.835 (+/-0.077) for {'learning_rate': 0.14000000000000001, 'n_estimators': 40}\n",
      "0.826 (+/-0.074) for {'learning_rate': 0.14000000000000001, 'n_estimators': 50}\n",
      "0.845 (+/-0.064) for {'learning_rate': 0.14000000000000001, 'n_estimators': 60}\n",
      "0.844 (+/-0.068) for {'learning_rate': 0.14000000000000001, 'n_estimators': 70}\n",
      "0.848 (+/-0.068) for {'learning_rate': 0.14000000000000001, 'n_estimators': 80}\n",
      "0.844 (+/-0.067) for {'learning_rate': 0.14000000000000001, 'n_estimators': 90}\n",
      "0.841 (+/-0.079) for {'learning_rate': 0.14000000000000001, 'n_estimators': 100}\n",
      "0.846 (+/-0.062) for {'learning_rate': 0.14000000000000001, 'n_estimators': 110}\n",
      "0.713 (+/-0.082) for {'learning_rate': 0.15000000000000002, 'n_estimators': 10}\n",
      "0.789 (+/-0.085) for {'learning_rate': 0.15000000000000002, 'n_estimators': 20}\n",
      "0.823 (+/-0.072) for {'learning_rate': 0.15000000000000002, 'n_estimators': 30}\n",
      "0.832 (+/-0.078) for {'learning_rate': 0.15000000000000002, 'n_estimators': 40}\n",
      "0.828 (+/-0.082) for {'learning_rate': 0.15000000000000002, 'n_estimators': 50}\n",
      "0.830 (+/-0.071) for {'learning_rate': 0.15000000000000002, 'n_estimators': 60}\n",
      "0.844 (+/-0.082) for {'learning_rate': 0.15000000000000002, 'n_estimators': 70}\n",
      "0.849 (+/-0.052) for {'learning_rate': 0.15000000000000002, 'n_estimators': 80}\n",
      "0.842 (+/-0.078) for {'learning_rate': 0.15000000000000002, 'n_estimators': 90}\n",
      "0.856 (+/-0.049) for {'learning_rate': 0.15000000000000002, 'n_estimators': 100}\n",
      "0.839 (+/-0.074) for {'learning_rate': 0.15000000000000002, 'n_estimators': 110}\n",
      "0.716 (+/-0.061) for {'learning_rate': 0.16, 'n_estimators': 10}\n",
      "0.791 (+/-0.087) for {'learning_rate': 0.16, 'n_estimators': 20}\n",
      "0.813 (+/-0.086) for {'learning_rate': 0.16, 'n_estimators': 30}\n",
      "0.830 (+/-0.067) for {'learning_rate': 0.16, 'n_estimators': 40}\n",
      "0.818 (+/-0.083) for {'learning_rate': 0.16, 'n_estimators': 50}\n",
      "0.832 (+/-0.078) for {'learning_rate': 0.16, 'n_estimators': 60}\n",
      "0.848 (+/-0.061) for {'learning_rate': 0.16, 'n_estimators': 70}\n",
      "0.841 (+/-0.068) for {'learning_rate': 0.16, 'n_estimators': 80}\n",
      "0.841 (+/-0.083) for {'learning_rate': 0.16, 'n_estimators': 90}\n",
      "0.847 (+/-0.070) for {'learning_rate': 0.16, 'n_estimators': 100}\n",
      "0.847 (+/-0.071) for {'learning_rate': 0.16, 'n_estimators': 110}\n",
      "0.716 (+/-0.099) for {'learning_rate': 0.17000000000000001, 'n_estimators': 10}\n",
      "0.803 (+/-0.070) for {'learning_rate': 0.17000000000000001, 'n_estimators': 20}\n",
      "0.823 (+/-0.070) for {'learning_rate': 0.17000000000000001, 'n_estimators': 30}\n",
      "0.834 (+/-0.072) for {'learning_rate': 0.17000000000000001, 'n_estimators': 40}\n",
      "0.839 (+/-0.063) for {'learning_rate': 0.17000000000000001, 'n_estimators': 50}\n",
      "0.840 (+/-0.062) for {'learning_rate': 0.17000000000000001, 'n_estimators': 60}\n",
      "0.849 (+/-0.058) for {'learning_rate': 0.17000000000000001, 'n_estimators': 70}\n",
      "0.845 (+/-0.079) for {'learning_rate': 0.17000000000000001, 'n_estimators': 80}\n",
      "0.848 (+/-0.070) for {'learning_rate': 0.17000000000000001, 'n_estimators': 90}\n",
      "0.849 (+/-0.060) for {'learning_rate': 0.17000000000000001, 'n_estimators': 100}\n",
      "0.849 (+/-0.079) for {'learning_rate': 0.17000000000000001, 'n_estimators': 110}\n",
      "0.732 (+/-0.075) for {'learning_rate': 0.18000000000000002, 'n_estimators': 10}\n",
      "0.803 (+/-0.077) for {'learning_rate': 0.18000000000000002, 'n_estimators': 20}\n",
      "0.803 (+/-0.078) for {'learning_rate': 0.18000000000000002, 'n_estimators': 30}\n",
      "0.851 (+/-0.054) for {'learning_rate': 0.18000000000000002, 'n_estimators': 40}\n",
      "0.836 (+/-0.077) for {'learning_rate': 0.18000000000000002, 'n_estimators': 50}\n",
      "0.851 (+/-0.074) for {'learning_rate': 0.18000000000000002, 'n_estimators': 60}\n",
      "0.841 (+/-0.082) for {'learning_rate': 0.18000000000000002, 'n_estimators': 70}\n",
      "0.832 (+/-0.071) for {'learning_rate': 0.18000000000000002, 'n_estimators': 80}\n",
      "0.841 (+/-0.081) for {'learning_rate': 0.18000000000000002, 'n_estimators': 90}\n",
      "0.846 (+/-0.084) for {'learning_rate': 0.18000000000000002, 'n_estimators': 100}\n",
      "0.850 (+/-0.058) for {'learning_rate': 0.18000000000000002, 'n_estimators': 110}\n",
      "0.750 (+/-0.079) for {'learning_rate': 0.19, 'n_estimators': 10}\n",
      "0.798 (+/-0.091) for {'learning_rate': 0.19, 'n_estimators': 20}\n",
      "0.830 (+/-0.075) for {'learning_rate': 0.19, 'n_estimators': 30}\n",
      "0.842 (+/-0.060) for {'learning_rate': 0.19, 'n_estimators': 40}\n",
      "0.841 (+/-0.073) for {'learning_rate': 0.19, 'n_estimators': 50}\n",
      "0.834 (+/-0.080) for {'learning_rate': 0.19, 'n_estimators': 60}\n",
      "0.846 (+/-0.070) for {'learning_rate': 0.19, 'n_estimators': 70}\n",
      "0.843 (+/-0.063) for {'learning_rate': 0.19, 'n_estimators': 80}\n",
      "0.843 (+/-0.070) for {'learning_rate': 0.19, 'n_estimators': 90}\n",
      "0.850 (+/-0.061) for {'learning_rate': 0.19, 'n_estimators': 100}\n",
      "0.853 (+/-0.061) for {'learning_rate': 0.19, 'n_estimators': 110}\n",
      "0.728 (+/-0.121) for {'learning_rate': 0.20000000000000001, 'n_estimators': 10}\n",
      "0.802 (+/-0.078) for {'learning_rate': 0.20000000000000001, 'n_estimators': 20}\n",
      "0.820 (+/-0.086) for {'learning_rate': 0.20000000000000001, 'n_estimators': 30}\n",
      "0.830 (+/-0.070) for {'learning_rate': 0.20000000000000001, 'n_estimators': 40}\n",
      "0.828 (+/-0.096) for {'learning_rate': 0.20000000000000001, 'n_estimators': 50}\n",
      "0.849 (+/-0.068) for {'learning_rate': 0.20000000000000001, 'n_estimators': 60}\n",
      "0.836 (+/-0.075) for {'learning_rate': 0.20000000000000001, 'n_estimators': 70}\n",
      "0.851 (+/-0.062) for {'learning_rate': 0.20000000000000001, 'n_estimators': 80}\n",
      "0.843 (+/-0.065) for {'learning_rate': 0.20000000000000001, 'n_estimators': 90}\n",
      "0.850 (+/-0.072) for {'learning_rate': 0.20000000000000001, 'n_estimators': 100}\n",
      "0.840 (+/-0.082) for {'learning_rate': 0.20000000000000001, 'n_estimators': 110}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "n_range = np.arange(1, 11)\n",
    "depth_range = np.arange(1, 11)\n",
    "split = np.arange(2, 11)\n",
    "n_range_1 = np.linspace(10, 110, 11, dtype=int)\n",
    "learn = np.linspace(0.01, 0.2, 20)\n",
    "\n",
    "tuned_parameters_1 = dict(n_estimators=n_range, max_depth=depth_range)\n",
    "tuned_parameters_2 = dict(max_depth=depth_range, min_samples_split=split)\n",
    "tuned_parameters_3 = dict(learning_rate=learn, n_estimators=n_range_1)\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=50)\n",
    "\n",
    "rfr = RandomForestRegressor()   \n",
    "dtr = DecisionTreeRegressor()\n",
    "gbr = GradientBoostingRegressor(subsample=0.8)\n",
    " \n",
    "clf = GridSearchCV(estimator=gbr, param_grid=tuned_parameters_3, cv=cv, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\" % (clf.best_params_, clf.best_score_))\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01,  0.02,  0.03,  0.04,  0.05,  0.06,  0.07,  0.08,  0.09,\n",
       "        0.1 ,  0.11,  0.12,  0.13,  0.14,  0.15,  0.16,  0.17,  0.18,\n",
       "        0.19,  0.2 ])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_range_1 = np.linspace(10, 110, 11, dtype=int)\n",
    "learn = np.linspace(0.01, 0.2, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97313063951\n",
      "0.855711855323\n",
      "0.846086762317\n"
     ]
    }
   ],
   "source": [
    "index = clf.best_index_\n",
    "train_score =  clf.cv_results_['mean_train_score'][index]\n",
    "test_score = clf.cv_results_['mean_test_score'][index]\n",
    "test_socre1 = clf.score(X_test, y_test)\n",
    "print(train_score)\n",
    "print(test_score)\n",
    "print(test_socre1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.103072102718\n",
      "0.234317427796\n"
     ]
    }
   ],
   "source": [
    "def per_err(y_true, y_pred):\n",
    "    err = np.average(np.abs(y_true - y_pred) / y_true)\n",
    "    return err\n",
    "\n",
    "print(per_err(y_train, clf.predict(X_train)))\n",
    "print(per_err(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.10865916,  0.24295282,  0.03980045,  0.0930608 ,  0.21714717,\n",
       "        0.05981359,  0.0922338 ,  0.08147721,  0.03116543,  0.03368958])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = clf.best_estimator_\n",
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "train_sizes=np.linspace(.1, 1.0, 10)\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, \n",
    "                                                        train_sizes=train_sizes, scoring='r2', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0xc38b860>]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc3543c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.18785832,  0.22863012,  0.3101679 ,  0.55895383,  0.57556972,\n",
       "        0.65442066,  0.73828279,  0.81499437,  0.84061979,  0.84089346])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores_mean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
